\section{Design and Implementation}
\label{sec:design-implementation}

In this section, we introduce our proposed monitoring framework, {\sysname}.
Section~\ref{subsec:overview-of-xmonitor} provides an overview of {\sysname}, Section~\ref{subsec:metrics-collection} explains the interface for metric collection, 
Section~\ref{subsec:non-blocking} describes the non-blocking monitoring, and Section~\ref{subsec:large-packet} illustrates how to process a large-sized packet within the XDP context.




\subsection{Overview}
\label{subsec:overview-of-xmonitor}

Fig.~\ref{fig:x-monitor} shows the overview of {\sysname}.
Upon receiving a packet, the Metrics Collector—an XDP program running on the eBPF virtual machine—is executed at an early stage, before the packet enters the network stack.
It first parses the packet header to determine whether the incoming packet is a monitoring packet.
If it is not, the program can invoke actions such as \texttt{XDP\_PASS} to forward the packet to the regular kernel processing pipeline, or \texttt{XDP\_DROP} to discard the packet.
If it is a monitoring packet, the collector retrieves the required metrics---both user-space and kernel-space---from within the kernel and sends them back to the monitoring client using \texttt{XDP\_TX}.

This monitoring approach achieves low latency, low overhead, and flexible metric selection for the following reasons.

\textbf{In-Kernel Monitoring. }
Monitoring with this approach incurs minimal overhead because both packet processing and metric collection are completed entirely within the kernel space, eliminating the need for user–kernel context switches.
In contrast, traditional monitoring systems incur multiple context switches—for example, when invoking the monitoring process or issuing system calls to retrieve kernel or user metrics—each introducing additional overhead.
By avoiding these context switches, our method reduces monitoring overhead.

\textbf{SoftIRQ-Layer Execution. }
Since monitoring is performed at the SoftIRQ layer, {\sysname} follows a run-to-completion execution model. 
In user-space approaches, as shown in the figure, delays can occur during both packet processing and metric collection due to contention for network stack locks or waiting for CPU scheduling. During metric collection, there is also a possibility that the CPU may be preempted by other processes. These delays become particularly significant in cloud environments where microservices are densely deployed.
In contrast, {\sysname} avoids such delays regardless of server load: there is no lock contention, no CPU scheduling delay, and no interruption except for HardIRQs. As a result, it achieves low-latency monitoring by minimizing both the time from packet arrival to processing and the time from packet processing to transmission.

\textbf{Programmable Metric Selection. }
In the proposed monitoring system, users can write custom monitoring logic as XDP programs and load them into the kernel.
This design enables in-kernel monitoring without sacrificing flexibility, as users have full control over which metrics to collect and how to collect them.
By defining their own programs, users can flexibly select the necessary metrics based on their specific monitoring goals.
Moreover, simple in-kernel computations can be performed on the collected metrics before sending them to the monitoring client, allowing for more efficient data handling when needed such as calculating the average CPU usage or detecting whether the memory usage exceeds a threshold.

\subsection{Interface for Metric Collection}
\label{subsec:metrics-collection}
To collect metrics from an XDP program, a key challenge arises: metric collection involves memory access that falls outside the bounds permitted by eBPF, which causes the program to fail verifier’s safety checks. 
To address this issue, we add BPF helper functions specifically designed for metric collection.
BPF helper functions are predefined interfaces in the Linux kernel that allow eBPF programs to interact with kernel objects or exchange data with the kernel.
While the verifier checks how a BPF helper function is called --- for example, ensuring type safety and calling context --- it does not analyze the internal behavior of the helper itself.
% This property allows us to safely extend the monitoring capabilities of XDP without compromising verifier security.
This property allows us to safely extend the monitoring capabilities of XDP without modifying the verifier, thereby preserving the kernel’s guarantees of memory safety and program isolation.
By introducing a dedicated BPF helper function for metrics access into the Linux kernel, {\sysname} can collect necessary metrics in their monitoring programs while still passing verifier’s checks.
This approach enables flexible and safe in-kernel monitoring within the constraints of the eBPF execution model.


\subsubsection{Collecting Kernel Metrics}

% \begin{table}[t]
%   \centering
%   % \small
%   \scriptsize
%   \caption{Kernel functions used to obtain metrics.}
%   \begin{tabular}{@{}lll@{}}
%     \toprule
%     Category & \texttt{/proc} File & \texttt{procfs} Internal Functions \\ \midrule
%     CPU      & \texttt{/proc/stat}         & \texttt{kcpustat\_cpu\_fetch()} \\
%     Disk     & \texttt{/proc/diskstats}    & \texttt{part\_stat\_read\_all()} \\
%     Memory   & \texttt{/proc/meminfo}      & 
%     \begin{tabular}[t]{@{}l@{}}
%       \texttt{si\_meminfo()} \\
%       \texttt{si\_swapinfo()} \\
%       \texttt{vm\_memory\_committed()} \\
%       \texttt{global\_node\_page\_state()} \\
%       \texttt{total\_swapcache\_pages()} \\
%       \texttt{si\_mem\_available()} \\
%       \texttt{global\_node\_page\_state\_pages()} \\
%       \texttt{global\_zone\_page\_state()}
%     \end{tabular} \\
%     Network  & \texttt{/proc/net/snmp}     & 
%     \begin{tabular}[t]{@{}l@{}}
%       \texttt{snmp\_get\_cpu\_field\_batch()} \\
%       \texttt{snmp\_get\_cpu\_field64\_batch()}
%     \end{tabular} \\
%     \bottomrule
%   \end{tabular}
%   \label{tab:procfs}

\begin{table}[t]
  \centering
  % \small
  \scriptsize
  \caption{Kernel functions used to obtain metrics.}
  \begin{tabular}{@{}lll@{}}
    \toprule
    Category & \texttt{/proc} File & \texttt{procfs} Internal Functions \\ \midrule
    CPU      & \texttt{/proc/stat}         & 
    \begin{tabular}[t]{@{}l@{}}
      \texttt{kcpustat\_cpu\_fetch()} \\
      \texttt{get\_idle\_time()} \\
      \texttt{get\_iowait\_time()} \\
      \texttt{kstat\_cpu\_irqs\_sum()} \\
      \texttt{arch\_irq\_stat\_cpu()} \\
      \texttt{kstat\_softirqs\_cpu()}
    \end{tabular} \\
    Disk     & \texttt{/proc/diskstats}    & \texttt{part\_stat\_read\_all()} \\
    Memory   & \texttt{/proc/meminfo}      & 
    \begin{tabular}[t]{@{}l@{}}
      \texttt{si\_meminfo()} \\
      \texttt{si\_swapinfo()} \\
      \texttt{vm\_memory\_committed()} \\
      \texttt{global\_node\_page\_state()} \\
      \texttt{total\_swapcache\_pages()} \\
      \texttt{si\_mem\_available()} \\
      \texttt{global\_node\_page\_state\_pages()} \\
      \texttt{global\_zone\_page\_state()}
    \end{tabular} \\
    Network  & \texttt{/proc/net/snmp}     & 
    \begin{tabular}[t]{@{}l@{}}
      \texttt{snmp\_get\_cpu\_field\_batch()} \\
      \texttt{snmp\_get\_cpu\_field64\_batch()}
    \end{tabular} \\
    \bottomrule
  \end{tabular}
  \label{tab:procfs}
\end{table}


To collect kernel metrics, the BPF helper functions utilize \texttt{procfs}, a pseudo file system commonly employed by traditional monitoring systems to expose runtime kernel information. By relying on the same interface as conventional user-space monitoring tools, the helper enables access to a wide range of kernel metrics, just as traditional monitoring processes do.

Files under \texttt{procfs} --- such as \texttt{/proc/stat}, \texttt{/proc/meminfo} --- are not backed by persistent storage, but are dynamically generated by kernel functions that read in-memory data structures.
These files expose metrics such as CPU usage, memory utilization, and network activity, most of which are maintained as continuously updated counters.
Because our BPF helper invokes the same internal functions used by procfs, it can access this rich set of metrics entirely within the kernel context, providing real-time visibility into kernel state as shown in Tab.~\ref{tab:procfs}.

This approach offers two key benefits.
First, it achieves the same level of observability as traditional user-space monitoring tools, while eliminating the overhead of context switches.
% Second, it is safe.
% The helper relies on well-defined, read-only kernel interfaces already used in production by procfs, avoiding unsafe memory access.
Second, memory safety is guaranteed because the helper simply invokes existing kernel-provided functions through well-defined interfaces already used in production by \texttt{procfs}. 
% Additionally, eBPF verifier statically checks helper usage to ensure memory safety and compliance with kernel constraints.
Additionally, memory access violations are avoided because the helper functions only invoke read-only kernel interfaces.
As long as the arguments are valid, these functions do not perform unsafe memory accesses.
eBPF verifier statically checks the types and value ranges of the arguments to ensure their correctness.
% The absence of blocking behavior is discussed in Sec.~\ref {subsec:non-blocking}.
The absence of blocking behavior is discussed in Sec.~\ref {subsec:non-blocking}.

\subsubsection{Collecting User Metrics}

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\columnwidth]{fig/user-metrics.pdf}
    % \caption{User Metrics Registration. Microservices register the metadata of metrics to metrics descriptor.}
    \caption{Overview of user-metric monitoring.
        Before monitoring, each microservice registers the address and size of its metric structs in a per-process metrics descriptor array.
        During monitoring, the BPF helper function retrieves the metrics descriptor array by indexing \texttt{port\_tab} with the microservice's port number and accesses the corresponding metric structs using the metadata stored in the array.}
    \label{fig:user-metric-collection}
\end{figure}

To efficiently retrieve user metrics from various microservices, it is crucial to support lightweight access to a diverse range of metrics.
As detailed in Sec.~\ref{sec:proposal}, to enable low-latency retrieval of user metrics from XDP programs, these metrics are placed in shared memory that is accessible from the kernel.
% Our design avoids invoking the APIs of the microservices to prevent interference.
Our design collects metrics equivalent to those obtained by conventional APIs while avoiding API invocation to prevent interference.



% Our system allows XDP programs to select which metrics to collect, aligning with existing monitoring tools.
% Memcached and Redis provide the `stats` and `INFO` commands, respectively, which enable monitoring tools to specify the metrics to be collected.
% Our design preserves this programmability while ensuring low latency and minimal overhead.

% \textbf{Preparation for Monitoring. }
% To enable XDP programs to retrieve user metrics, two preparatory steps are necessary. 

% First, each user process must register its metrics with the kernel.
% User metrics are defined by each microservice and are typically organized into multiple C structs (or equivalent representations) that store a set of performance-related fields.
% For instance, Memcached utilizes seven metric structures, including \texttt{struct settings} and \texttt{struct rusage}.
% This is done through a custom system call called \texttt{xmon\_reg\_metrics}, which allows the kernel to locate where the metrics are stored (the starting virtual address and the size of the metrics).
% This call is invoked multiple times to register all structures related to the metrics.
% The registered information is stored in a \emph{metrics descriptor} array allocated for each user process.
% A \emph{metric descriptor}, which is an index into the descriptor array, is returned to the microservice.
% When registering, the starting virtual address of the metrics is converted into a physical address.
% The physical pages containing the metrics remain constant during execution, as discussed in Sec.~\ref{subsec:non-blocking}.
% Since the kernel can access any physical address, the helper function can retrieve the registered metrics without needing address translation.

% Second, after registering all relevant metric information, the microservice registers a port number that allows a monitoring client to access the user metrics. This port number is associated with the metrics descriptor array; thus, given the port number, an XDP program can look up the corresponding array and collect the user metrics from the registered addresses.


\textbf{Preparation for Monitoring. }
To allow XDP programs to access metrics in shared memory, each metric must be registered with the kernel in advance, including its address, size, and the monitored process's port number.
To store this information, {\sysname} maintains a per-process metrics descriptor array, which holds the address and size of each metric struct exposed by the process (Fig.~\ref{fig:user-metric-collection}).
User-level metrics are typically organized as multiple C structs.
For example, Memcached stores its metrics in several structs, such as \texttt{struct stats} and \texttt{struct settings}.
Following this design, {\sysname} registers metrics at the granularity of these metric structs rather than individual fields, which reduces the number of helper function invocations.

When a monitored process starts, it opens \texttt{/dev/xmon}.
% At this point, no metric information has been registered yet, but the file descriptor returned by \texttt{open} is associated with a per-process context that will later hold the metrics descriptor array.
At this point, the file descriptor returned by \texttt{open} is associated with a per-process context that will later hold the metrics descriptor array.
Metric information is registered via three custom ioctls invoked on this file descriptor.
The first ioctl, \texttt{XMON\_IOC\_CREATE}, takes as an argument the number of metric structs and allocates a metrics descriptor array with that number of elements.
% The second ioctl, \texttt{XMON\_IOC\_SET\_ELEM}, is invoked once per metric struct.
% It receives the struct's starting address and size as arguments and stores them in the appropriate element of the metrics descriptor array.
The second ioctl, \texttt{XMON\_IOC\_SET\_ELEM}, receives the starting address and size of each metric struct as arguments and stores them in the corresponding entry of the metrics descriptor array.
It is invoked once per metric struct.
During this registration, the ioctl converts the virtual address to a physical address.
This conversion enables XDP programs --- which run in a different address space from the monitored process --- to access the metrics, and it also allows {\sysname} to operate correctly even when KPTI is enabled as part of Meltdown mitigations.
Furthermore, \texttt{XMON\_IOC\_SET\_ELEM} pins the pages of the registered memory region to prevent blocking caused by swap-in during monitoring (see Sec.~\ref{subsec:non-blocking}).
% The third ioctl, \texttt{XMON\_IOC\_REGISTER\_PORT}, takes a port number as its argument and updates the global \texttt{port\_tab} array so that the entry for that port points to the metrics descriptor array created earlier.
% The third ioctl, \texttt{XMON\_IOC\_REGISTER\_PORT}, takes a port number as its argument and updates the global \texttt{port\_tab} array so that \texttt{port\_tab[port]} points to the metrics descriptor array created earlier.
The third ioctl, \texttt{XMON\_IOC\_REGISTER\_PORT}, takes a port number as its argument and updates the global \texttt{port\_tab} array --- an array that stores, for each microservice port number, a pointer to its corresponding metrics descriptor array --- so that \texttt{port\_tab[port]} points to the metrics descriptor array created earlier.
In addition, \texttt{XMON\_IOC\_REGISTER\_PORT} verifies that the specified port number actually belongs to the process invoking the ioctl, and it performs the registration only if this association is confirmed. 
This prevents a process from falsely registering an arbitrary port number.
With these preparations, the helper function for retrieving user metrics can access the target metrics in O(1) time by simply receiving the port number of the monitored microservice as an argument.


% {\sysname}'s helper function retrieves user metrics and copies them into a network packet.
% To allow an XDP program to select specific user metrics, it requires an array of metric descriptors as arguments.
% The user metrics stored in the specified descriptors are copied into the packet, while the metrics not specified are omitted.
% This helper function operates in a lock-free manner because it performs read-only operations on the user metrics and the descriptor array (see Sec.~\ref{subsec:non-blocking}).
% Importantly, this design remains effective even if kernel space is separated from user space as a mitigation against Meltdown, since user metrics are accessed through their physical addresses.

One important consideration is that if a user metric registered in the metrics descriptor array exceeds 4 KB in size, it may span multiple physical memory pages.
In such cases, the helper might unintentionally read data from a different, unrelated kernel memory page.
To prevent this issue, the user metrics should be split into smaller components before being registered in the metrics descriptor array.

\textbf{Lifecycle of Monitored Microservice. }
The lifecycle of the monitored microservice consists of minimally intrusive allocation of monitoring resources at startup and their safe release when the service terminates.
The monitored microservice registers its metrics only once when it starts up.  
This registration completes within approximately 50 $\mu$s.  
During execution, the microservice continues running without being interrupted for monitoring (except for unavoidable Hard IRQs).  
In contrast, traditional monitoring requires invoking monitoring APIs during execution---such as \texttt{stats} in Memcached or \texttt{INFO} in Redis---which interferes with the microservice’s normal operation.

When the microservice terminates, {\sysname} safely releases all resources.  
When the file descriptor returned by open(/dev/xmon) is closed at process exit, the kernel invokes \texttt{xmon\_release}.  
\texttt{xmon\_release} clears the corresponding entry in \texttt{port\_tab} by setting it to NULL, and then frees the associated metrics descriptor array.  
This prevents use-after-free bugs and ensures safe cleanup.  
The same cleanup procedure is triggered even when the microservice crashes or is restarted: closing the file descriptor automatically calls \texttt{xmon\_release} and releases the metrics descriptors in the same way.  
If the process crashes, the corresponding \texttt{port\_tab} entry becomes NULL, causing no metrics to be returned, which immediately alerts the system administrator to the anomaly.


\subsection{Non-Blocking Monitoring}
\label{subsec:non-blocking}
Since XDP programs execute in the SoftIRQ context, they must not cause any blocking.
Blocking operations in such interrupt contexts can delay the handling of other interrupts or kernel tasks, potentially degrading overall system responsiveness.
To ensure safe and efficient monitoring, it is therefore crucial that metric collection remains non-blocking—specifically, it must avoid lock acquisition and prevent access to memory regions that may have been swapped out.
% This design principle helps guarantee the safe execution of monitoring logic within the kernel.

% \textbf{Kernel Metrics. }
% To determine whether any blocking occurs inside \texttt{procfs}, we analyzed the internal functions listed in Tab.~\ref{tab:procfs}, which are used to retrieve kernel metrics.

% \emph{CPU metrics.}
% Most of the kernel functions listed in Table~\ref{tab:kernel-func} internally invoke
% \texttt{per\_cpu\_ptr()}, which simply performs address arithmetic on per-CPU memory regions and does not acquire any locks.
% Even the remaining functions, such as \texttt{get\_iowait\_time()}, rely on \texttt{atomic\_read()}, which is also a lock-free operation.

% \emph{Disk metrics. }
% Disk statistics involve RCU read-side critical sections.
% RCU read locks do not block and are safe within SoftIRQ.
% Furthermore, functions such as \texttt{part\_stat\_read\_all()} use
% \texttt{per\_cpu\_ptr()} to aggregate per-CPU counters, identical to those used
% for CPU metrics, and therefore do not acquire blocking locks.

% \emph{Memory metrics. }
% Memory-related statistics show heterogeneous locking behavior.
% Several commonly used helpers internally acquire spinlocks, including
% \texttt{si\_meminfo()}, \texttt{si\_swapinfo()}, and \texttt{vm\_memory\_committed()}.
% Because spinlock acquisition is incompatible with SoftIRQ execution,
% {\sysname} does not collect memory metrics that rely on these functions.
% In contrast, other memory-related functions mostly read counters using \texttt{atomic\_long\_read()}, which does not acquire spinlocks.
% These metrics can therefore be accessed safely without blocking.

% \emph{Network metrics. }
% Network statistics collecting function iterate over per-CPU SNMP counters via \texttt{per\_cpu\_ptr()}.
% As with CPU and disk metrics, these helpers do not acquire blocking locks and do not invoke sleepable operations.
% Thus, network metrics can be obtained safely from the SoftIRQ context.

\textbf{Kernel Metrics.}
To determine whether any blocking occurs inside \texttt{procfs}, we analyzed the internal functions listed in Tab.~\ref{tab:procfs}, which are used to retrieve kernel metrics.
With respect to CPU metrics, most of the functions internally invoke \texttt{per\_cpu\_ptr()}, which merely performs address arithmetic on per-CPU memory regions and does not acquire any locks.
Even the exceptional functions, such as \texttt{get\_iowait\_time()}, use \texttt{atomic\_read()}, which is likewise lock-free.
For disk metrics, the corresponding functions operate within RCU read-side critical sections; RCU read locks are non-blocking~\cite{rcu} and safe in SoftIRQ context.
Moreover, kernel functions such as \texttt{part\_stat\_read\_all()} aggregate per-CPU counters via \texttt{per\_cpu\_ptr()}, identical to CPU metric retrieval, and therefore do not acquire blocking locks.
Memory metrics exhibit more heterogeneous behavior: several widely used functions, including \texttt{si\_meminfo()}, \texttt{si\_swapinfo()}, and \texttt{vm\_memory\_committed()}, internally acquire spinlocks, which makes them incompatible with SoftIRQ execution.
Accordingly, {\sysname} avoids collecting memory metrics that depend on these functions.
Other memory-related functions simply read counters through \texttt{atomic\_long\_read()}, which does not acquire spinlocks and is therefore safe within SoftIRQ.
Finally, network metrics are obtained by iterating over per-CPU SNMP counters using \texttt{per\_cpu\_ptr()}, which, as in the CPU and disk cases, acquires blocking locks.

% In addition, it is known that kernel metrics are never swapped out ~\cite{zero}.
% Therefore, metric collection via \texttt{procfs} can be performed without blocking, ensuring safe monitoring within the kernel.
With respect to whether kernel metrics may be swapped out, prior work shows that these kernel-resident data structures are never paged out~\cite{zero}.
Therefore, metric collection via \texttt{procfs} can be performed without blocking, ensuring safe monitoring within the kernel.


\textbf{User Metrics. }
% For user metrics, the systyem is designed to avoid acquiring locks during both metadata access and metric reading.
For user metrics, {\sysname} does not acquire locks during metadata access or metric reading because both operations are read-only and do not require synchronization.
However, user metrics may be subject to swap-out if no specific configuration is applied.
% To prevent blocking due to swapping, microservices are configured to pin the relevant memory using the \texttt{mlock} system call prior to monitoring.
To prevent blocking due to swapping, {\sysname} pins the relevant memory using the \texttt{mlock} system call before monitoring begins.


\subsection{Handling Large Size Packet}
\label{subsec:large-packet}
% BPF の最大スタックサイズの拡張および，XDP multi buffer の話をする．multibuffer をどう使えるかも書く

When using XDP for monitoring, one key limitation is the maximum packet size that XDP can handle.
XDP is not originally designed to process large packets, and therefore imposes restrictions on the size of packets it can operate on.
However, monitoring often involves collecting a large number of metrics from each microservice, which requires processing larger packets.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.7\columnwidth]{SoCC-2025/figures/illustration/xdp-multi-buffer.pdf}
%     \caption{XDP multi-buffer. The first buffer can be accessed through the \texttt{data} and \texttt{data\_end} members of the \texttt{xdp\_buff} structure. With multi-buffer support, additional buffers beyond the first one can be accessed via \texttt{skb\_shared\_info}, enabling the handling of multiple buffers.}
%     \label{fig:xdp-multi-buffer}
% \end{figure}

\textbf{XDP multi buffer support. }
XDP does not natively support the transmission or reception of packets that exceed the Maximum Transmission Unit (MTU).
Typically, the MTU is set to 1500 bytes, and even with Jumbo Frames, it is extended only up to 9000 bytes~\cite{jumbo-frame}.
Since monitoring involves collecting metrics from multiple microservice instances on a server simultaneously, this packet size is often insufficient.
For instance, each Memcached instance returns 656 bytes of metrics.


To overcome this limitation, the support for XDP multi-buffer~\cite{multibuffer, multibuffer-2}, introduced in Linux 5.18, enables the processing of packets larger than the MTU.
Conventional XDP programs assume a single buffer per packet and access packet contents using the \texttt{.data} and \texttt{.data\_end} pointers, which indicate the start and end addresses of the packet data.
eBPF verifier ensures memory safety by checking that all accesses fall within this range.
As a result, it was not possible to access data beyond a single buffer.
XDP multi-buffer addresses this limitation by allowing access to additional buffers through the \texttt{skb\_shared\_info} structure.
This capability makes it possible to process sufficiently large packets required for monitoring purposes.

\textbf{BPF Stack size extension. }
The BPF stack has a limited size, which restricts the amount of local memory available to eBPF programs.
In Linux, the maximum BPF stack size is currently limited to 512 bytes, as defined by the macro \texttt{MAX\_BPF\_STACK}.
However, this size is often insufficient for practical monitoring use cases.
For instance, in the case of Memcached, existing monitoring tools collect metrics that require 656 bytes per instance, which already exceeds the default stack limit.
Moreover, as the number of monitored microservices increases, the memory required to store their corresponding metrics grows proportionally, further stressing the BPF stack usage.

eBPF does not provide general-purpose helper functions for dynamically allocating temporary local memory, as eBPF verifier must statically prove the memory safety of all accesses.
Unlike the stack, which has a fixed size and a well-defined layout, dynamically allocated memory is difficult to verify due to uncertain lifetimes, pointer aliasing, and type ambiguity.
Therefore, it is difficult to introduce custom helper functions that extend local memory, as their accesses cannot be precisely verified at verification time.

To address this limitation while preserving memory safety guarantees, we increased the value of \texttt{MAX\_BPF\_STACK} in the Linux kernel, thereby enabling our monitoring system to allocate a larger BPF stack size sufficient to store the necessary metrics.


\subsection{Modification for Monitored Microservice. }
\textbf{Applying {\sysname} to Memcached. }
\label{subsec:case-study}
In this section, we present a case study to illustrate how {\sysname} collects both user and kernel metrics.  
We use Memcached metrics as a representative example of user metrics.  
% For kernel metrics, we focus on CPU-related statistics.
For kernel metrics, although {\sysname} supports various types, we focus on CPU-related statistics.

\textbf{Monitoring Memcached Metrics. }
Memcached is a widely used in-memory database in cloud environments.  
Due to its simplicity and high performance, as well as its support for distributed caching, it has been adopted in large-scale web services and microservice-based architectures.  
In traditional monitoring approaches, a monitoring process sends the \texttt{stats} command to Memcached.  
Upon receiving the request, Memcached invokes its internal metric collection functions---\texttt{server\_stats()} and \texttt{get\_stats()}---to selectively retrieve metrics from a set of predefined data structures.

These structures include seven types: \texttt{stats}, \texttt{stats\_state}, \texttt{rusage}, \texttt{slab\_stats}, \texttt{settings}, \texttt{thread\_stats}, and \texttt{itemstats\_t}.  
Although the combined size of these structures is approximately 7,440 bytes, the actual size of the metrics returned to the client is only about 656 bytes.  
Therefore, Memcached selectively collects only the required metrics from each structure.

In contrast, the proposed approach minimizes the involvement of Memcached during monitoring.  
Memcached only registers metrics information prior to monitoring; it plays no active role during runtime metric collection.  
% Moreover, {\sysname} rearranges the member fields of the metric-holding structures so that monitored metrics are placed at the beginning and unmonitored ones at the end.  
% This layout allows BPF programs to collect metrics efficiently, thereby collecting the necessary metrics with minimal overhead.
Moreover, {\sysname} rearranges the fields of the metrics structure so that only the required metrics are placed consecutively at the beginning of the structure.
This allows efficient retrieval of the necessary metrics in a single access.

\textbf{Monitoring CPU Metrics. }
For collecting CPU metrics, both conventional methods and {\sysname} retrieve metrics via \texttt{procfs}.
In traditional approaches, a system call is issued to access \texttt{procfs}, resulting in user–kernel context switch overhead.
In contrast, {\sysname} invokes \texttt{procfs} from within a BPF helper function, thereby eliminating the overhead of context switches.

Specifically, BPF helper calls \texttt{part\_stat\_read\_all()}, a function defined inside \texttt{procfs}.
This function internally invokes a series of other functions, eventually calling the macro \texttt{RELOC\_HIDE} to access CPU metrics.
Throughout this entire code path, no locks are acquired.
As a result, {\sysname} ensures safe monitoring from within XDP, without introducing any blocking due to lock contention.

\textbf{Applying {\sysname} to Redis. }